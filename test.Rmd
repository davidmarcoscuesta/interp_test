---
title: "Testing Interpolation"
author: "David Cuesta"
date: "2025-01-19"
output: html_document
---

```{r}
library(tidyverse)
library(imputeTS) # Interpolation 
library(dplyr)
library(pracma)
```

```{r}
# Load the .rds file
merged_df <- readRDS("merged_vrg_dataset_with_velocities.rds")
# downsampled_df <- readRDS("vrg_downsampled_dataset.rds")
# interpolated_df <- readRDS("vrg_interpolated_dataset.rds")

# View the structure of the object
str(interpolated_df)
# head(downsampled_df)
names(merged_df)
# summary(downsampled_df)
```

```{r}
# Remove rows with NA values in key velocity columns
cleaned_df <- merged_df %>%
  filter(!is.na(ang_vel) & !is.na(euc_vel))

# Save the cleaned dataset
saveRDS(cleaned_df, "merged_vrg_dataset_with_velocities_cleaned.rds")

write.csv(cleaned_df, "vrg_raw_cleaned.csv", row.names = FALSE)

```

# 

```{r}
# Define the target frequencies
cleaned_target_dt <- 1 / 250  # 250 Hz => 0.004 seconds
downsampled_target_dt <- 1 / 125  # 125 Hz => 0.008 seconds

# Select the dataset you want to process (either cleaned_df or downsampled_df)
target_df <- cleaned_df  # Replace with downsampled_df for 125 Hz

# Initialize an empty dataframe to store interpolated data
interpolated_data <- NULL

# Loop through each participant/session
unique_trials <- unique(target_df %>% select(participant_id, session))

for (trial in 1:nrow(unique_trials)) {
  # Filter data for the current participant/session
  cur <- target_df %>%
    filter(participant_id == unique_trials$participant_id[trial],
           session == unique_trials$session[trial])
  
  # Define target time step based on dataset
  target_dt <- ifelse(identical(target_df, cleaned_df), cleaned_target_dt, downsampled_target_dt)
  
  # Compute cumulative time
  cur_time <- cumsum(cur$dt)
  
  # Define uniform time points for interpolation within the range of cur_time
  interp_points <- seq(from = min(cur_time, na.rm = TRUE), 
                       to = max(cur_time, na.rm = TRUE), 
                       by = target_dt)
  
  # Interpolate x and y coordinates
  interp_x <- pracma::interp1(x = cur_time, y = cur$x, xi = interp_points, method = "linear")
  interp_y <- pracma::interp1(x = cur_time, y = cur$y, xi = interp_points, method = "linear")
  
  # Create a dataframe for the interpolated trial
  newdata <- data.frame(
    participant_id = unique(cur$participant_id),
    session = unique(cur$session),
    t = interp_points,
    x = interp_x,
    y = interp_y
  )
  
  # Append to the final interpolated dataset
  if (is.null(interpolated_data)) {
    interpolated_data <- newdata
  } else {
    interpolated_data <- bind_rows(interpolated_data, newdata)
  }
}

# Save the interpolated data
write.csv(interpolated_data, "interpolated_raw_dataset.csv", row.names = FALSE)


```



# Downsampling from 250 to 125 Hz
```{r}
cleaned_df <- readRDS("merged_vrg_dataset_with_velocities_cleaned.rds")
```

```{r}
downsampling_factor <- 2

downsampled_df <- cleaned_df %>%
  group_by(participant_id, session, task) %>%
  filter(row_number() %% downsampling_factor == 1) %>%
  ungroup()

# saveRDS(downsampled_df, "vrg_downsampled_dataset_without_nas.rds")

```

# Interpolate from 125 to 250 Hz

- Python: Numpy or pandas interpolated function
- R: 

- Cubic Spline Interpolation: Ensures smooth transitions, especially suitable for continuous movements like gaze data.
- Radial Basis Function (RBF) Interpolation: Handles irregularly spaced data points, which might occur in your dataset.
- Polynomial Interpolation (e.g., Lagrange): Useful for small segments but prone to oscillations in larger datasets.
- Piecewise Linear Interpolation: Simpler but may not capture smooth gaze trajectories. 

```{r}
# Postpro
downsampled_df <- readRDS("vrg_downsampled_dataset_without_nas.rds")

# write.csv(downsampled_df, "downsampled_df.csv", row.names = FALSE)
```

# Reconstruct Time

```{r}
# Compute time column for each participant
cleaned_df <- cleaned_df %>%
  group_by(participant_id, session) %>%  # Group by participant and session
  mutate(time = cumsum(dt)) %>%          # Compute cumulative sum of dt within each group
  ungroup()  
```

```{r}
# Compute time column for each participant
downsampled_df <- downsampled_df %>%
  group_by(participant_id, session) %>%  # Group by participant and session
  mutate(time = cumsum(dt)) %>%          # Compute cumulative sum of dt within each group
  ungroup()                              # Remove grouping for further analysis
```


# Checking Fz 
```{r}
# Check the time interval within each group
sampling_intervals <- cleaned_df %>%
  group_by(participant_id, session, task) %>%
  summarise(
    mean_interval = mean(diff(n), na.rm = TRUE)  # Mean interval in milliseconds
  ) %>%
  ungroup()

# View the results
print(sampling_intervals)
```
```{r}
# Add frequency calculation
sampling_frequency <- sampling_intervals %>%
  mutate(
    frequency_hz = 1000 / mean_interval  # Convert ms to Hz
  )

# View the results
print(sampling_frequency)

```

```{r}
# Overall mean frequency
overall_frequency <- mean(sampling_frequency$frequency_hz, na.rm = TRUE)

# Range of frequencies
frequency_range <- range(sampling_frequency$frequency_hz, na.rm = TRUE)

# Print the results
cat("Overall Frequency (Hz):", overall_frequency, "\n")
cat("Frequency Range (Hz):", frequency_range, "\n")
```

